<html>
<body>
<div style="width: 800px">
    <h1> Assignment 6 - Video Textures </h1>
    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> introduction </h2>
        <p> In this assignment we will be applying our computational photography magic to video, with the purpose of creating video textures, or infinitely looping pieces of video. </p>
        <p> The input and output for the homework assignment is provided as a folder of images. The reasoning behind this, and suggestions for moving between different formats of video are given in the video Appendix in section 4. </p>
        <p> The files in this homework can be downloaded <a href="http://www.dcastro.me/cs4475/summer2013/assignment6/files.zip"> here </a> and contain the following files: </p>
        <ul>
            <li> <strong>part0.py, part1.py, part2.py</strong> - contain the code you need to finish in order to complete the homework assignment. Each file also contains test functions for you to debug your code. </li>
            <li> <strong> run.py </strong> - contains code in order to take a video, find the largest loop in that video, and render the loop separately. </li>
            <li> <strong> split.py </strong> - convert a video file into a folder of images (details in appendix) </li>
            <li> <strong> merge.py </strong> - convert a folder of images into a video file (details in appendix) </li>
            <li> <strong> output (folder) </strong> - contains sample images for you to run your code on. </li>
            <li> <strong> readme.html </strong> - contains these instructions. </li>
        </ul>
    </div>

    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> part 0 - video_volume and SSD </h2>
        <h3 style="color:black;"> video_volume </h3>
        <p> Hopefully, while implementing this function you will get more familiar with the 4d coordinate system of a video volume (time x row x column x channel). Your task is to take a list containing image numpy arrays, and turn them into a single array which contains the entire video volume. </p> 
        <p> The lectures, as well as the documentation string in the file contains further detail. </p>
        <h3 style="color:black;"> ssd </h3>
        <p> In this function, you will find an image distance between every pair of frames in the video, as discussed in lecture. SSD stands for sum of square distances, which as the name suggests, requires you to take the pixelwise difference of the two frames, square it, and sum them all together. </p>
        <p> The documentation string in the file contain further detail. When you’re finished with your code, the function run.py will save a visualization of the difference matrix generated by this function in the video/out folder. </p>
    </div>
    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> part 1 - diff2 </h2>
        <p> This function takes in a difference matrix created by ssd, and updates it with dynamic information. </p>
        <p>The intuition behind this is as follows when considering the transition cost from frame i to j, we should not only look at the frames themselves, but also consider the preceding and following frames. </p>
        <p> So, </p>
        <img src="http://www.dcastro.me/cs4475/summer2013/assignment6/images/func-diff2.jpg" />
        <p> Or, in other words, we are going to take a weighting function, and sum across the ssd outputs of the preceding and following frames in order to update the transition costs with dynamic information. </p>
        <p> For this assignment, you will be using a binomial filter, which is given to you in the code. For more details about this filter, consult the video textures paper and further references at the end of this document. </p>
        <p> The documentation string, and the lectures have further information. When you are finished with the assignment, run.py will save a visualization of this matrix in the video/out folder. </p>
    </div>
    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> part 2 - find_biggest_loop and synthesize_loop </h2>
        <h3 style="color:black;"> find_biggest_loop </h3>
        <p> Now that we have the costs of transitioning from one frame to another, we should find a suitable loop for our video texture. Simply taking the smallest transition distance here might not be desirable what if the resulting loop is only 1 frame long? </p>
        <p> In order to state within the code that loop size matters, we will use a trick that is frequent in engineering disciplines. </p>
        <p> We are going to find the transition which is optimal under a metric: </p>
        <img src="http://www.dcastro.me/cs4475/summer2013/assignment6/images/func-score.jpg" />
        <p> Note the two terms of the metric. The first is the difference between the final and starting frame of our loop. This term is large when the loop is large. The second term is the output of our diff2 function, which tells us the cost of transitioning from finish to start. Subtracting this term turns it into a ‘smoothness’ parameter. It is larger when the transition is less noticeable. </p>
        <p> The last bit of wizardry is the alpha parameter. Because the size of the loop and the transition cost are likely to be in very different units, we introduce a new parameter to make them comparable. We can manipulate alpha to control the tradeoff between loop size and smoothness. Large alphas prefer large loop sizes, and small alphas prefer smoother transitions.</p>
        <p> Your find_biggest_loop function has to compute this score for every choice of s and f, and return the s and f that correspond to the largest score. </p>
        <p> The documentation string has further details. As with previous score matrixes, run.py will visualize this when you’re finished with the programming assignment. </p>
        <h3 style="color:black;"> synthesize_loop </h3>
        <p>The finishing step is to take our video volume, and turn it back into a series of images, now cropping it to only contain the loop we found. This function does just that. It is pretty much the inverse of the video_volume function you implemented earlier, except for this time you’re starting with a full video volume, and you are returning a list of only the image frames between start and finish (inclusive).</p>
        <p> The documentation string contains details. Once you’re finished with this, give yourself a pat on the back (or a hug). You’re done with the homework assignment! </p>
    </div>
    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> appendix - video </h2>
        <p>As was mentioned in lecture, working with video is still not very user friendly. This is especially so when using free tools, it is very difficult to guarantee that a particular video codec will work on a given system. In order to avoid such issues, this assignments inputs and outputs are sequences of numbered images.</p>
        <p> There are tools, discussed in this appendix, that will allow you to split your videos into frames, and put them back together into videos. </p>
        <h3 style="color:black;"> python </h3>
        <p> OpenCV for python does support dealing with video, however this support is inconsistent across methods of installation and operating systems. If you have an installation capable of dealing with video, or you want to invest the time to set one up, this week’s assignment comes with two files, ‘split.py’ and ‘merge.py’ that handle the conversion between frame images and video, as their names suggest. </p>
        <p> To split a video into frames, run this in terminal: </p>
        <p style="font-style: italic"> python split.py path/to/video.avi </p>
        <p> To merge a folder of images into video, run this in terminal: </p>
        <p style="font-style: italic"> python merge.py path/to/image/folder/ </p>
        <p> You may have to change video formats and the output fourcc codec in order to make this work on your system. For details, see: </p>
        <p> <a href="http://opencv.willowgarage.com/wiki/documentation/cpp/highgui/VideoWriter"> OpenCV VideoWriter </a> </p>
        <p> <a href="http://opencv.willowgarage.com/wiki/VideoCodecs"> OpenCV VideoCodecs </a> </p>
        <p> <a href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/highgui/doc/reading_and_writing_images_and_video.html?videowriter-videowriter#videowriter"> OpenCV - Reading and Writing Images and Video </a> </p>
        <h3 style="color:black;"> animated gif (gifsicle) </h3>
        <p> Instead of video, another option is to create an animated gif. Many products, like photoshop, are capable of doing this. In this section we will discuss gifsicle, available <a href="http://www.icdf.org/gifsicle/">here</a>.</p>
        <p> This is a tool for creating animated gifs. Unfortunately, gifsicle is only compatible with gifs, and opencv is not, so you will have to convert the frame images from png format to gif format. Again, there are lots of tools for doing this in batch, like <a href="http://www.imagemagick.org/script/index.php"> imagemagick</a>.</p>
        <p> We are hoping that if you are motivated you will be able to use the install and support pages to use these programs. </p>
        <h3 style="color:black;"> ffmpeg (avconv) </h3>
        <p> ffmpeg is available <a href="http://www.ffmpeg.org"> here</a>.</p>
        <p> This is a free and very widely used software for dealing with video and audio. Once you have it installed, you can use this command to split your video into frames: </p>
        <p style="font-style: italic"> ffmpeg -i video.ext -r 1 -f image2 image_directory/%04d.png </p>
        <p> And this command to put them back together: </p>
        <p style="font-style: italic"> ffmpeg -i image_directory/%04d.png out_video.ext </p>
    </div>
    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> references </h2>
        <ul>
        <li><a href="http://docs.scipy.org/doc/">numpy and scipy</a></li>
        <li><a href="http://docs.scipy.org/doc/numpy/user/index.html#user">numpy user guide</a></li>
        <li><a href="http://docs.opencv.org/">opencv</a></li>
        <li><a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html">scipy.signal.convolve2d</a></li>
        <li><a href="http://www.cse.yorku.ca/~kosta/CompVis_Notes/binomial_filters.pdf">binomial filters</a></li>
        <li><a href="http://www.cc.gatech.edu/cpl/projects/videotexture/">video textures</a></li>
        <li><a href="http://www.youtube.com/watch?v=O0eEuCxGiAE&feature=youtu.be">very important link</a></li>
        </ul>
    </div>
    <div>
        <h2 style="color: black; margin-top: 15px; margin-bottom: 15px; padding-bottom: 15px; padding-top: 15px; padding-left: 30px; border-bottom: 1px solid #000; border-top: 1px solid #000;"> submission </h2>
        <p> Please note, we want you to <strong>use your own video or images, be creative! </strong> </p>
        <p> Aside from the code include a small writeup of your choice of video, and what problems you encountered and any other thoughts. </p>
        <img src="http://www.dcastro.me/cs4475/summer2013/assignment6/images/submission.jpg" />
    </div>
</div>
</body>
</html>